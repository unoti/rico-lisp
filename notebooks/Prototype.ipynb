{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference [Peter Norvig](https://norvig.com/lispy.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just make a simple calculator.  We want to be able to use it like:\n",
    "```\n",
    "(define r 10)\n",
    "(* pi (* r r))\n",
    "```\n",
    "\n",
    "```\n",
    ">> program = \"(begin (define r 10) (* pi (* r r)))\"\n",
    "\n",
    ">>> parse(program)\n",
    "['begin', ['define', 'r', 10], ['*', 'pi', ['*', 'r', 'r']]]\n",
    "\n",
    ">>> eval(parse(program))\n",
    "314.1592653589793\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symbol = str              # Symbol is implemented as a Python str\n",
    "Number = (int, float)     # Number is implemented as either a Python int or float\n",
    "Atom   = (Symbol, Number) # An Atom is a Symbol or Number\n",
    "List   = list             # List is implemented as a Python list\n",
    "Exp    = (Atom, List)     # An expression is either an Atom or List\n",
    "Env    = dict             # An environment is a mapping of {variable: value}. Dict for now; we'll expand later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(chars: str) -> list:\n",
    "    \"\"\"\n",
    "    Convert a string of characters into a list of tokens.\n",
    "    \"\"\"\n",
    "    return chars.replace('(', ' ( ').replace(')', ' ) ').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', 'begin', '(', 'define', 'r', '10', ')', '(', '*', 'pi', '(', '*', 'r', 'r', ')', ')', ')']\n"
     ]
    }
   ],
   "source": [
    "program = \"(begin (define r 10) (* pi (* r r)))\"\n",
    "print(tokenize(program))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(program: str) -> Exp:\n",
    "    \"\"\"\n",
    "    Read a string and turn it into an Expression.\n",
    "    \"\"\"\n",
    "    return read_from_tokens(tokenize(program))\n",
    "\n",
    "def read_from_tokens(tokens: list) -> Exp:\n",
    "    \"\"\"\n",
    "    Read an expression from a sequence of tokens.\n",
    "    \"\"\"\n",
    "    if len(tokens) == 0:\n",
    "        raise SyntaxError('unexpected EOF')\n",
    "    \n",
    "    token = tokens.pop(0)\n",
    "    if token == '(':\n",
    "        L = []\n",
    "        while tokens[0] != ')':\n",
    "            L.append(read_from_tokens(tokens))\n",
    "        tokens.pop(0) # pop off ')'\n",
    "        return L\n",
    "    \n",
    "    if token == ')':\n",
    "        raise SyntaxError('unexpected )')\n",
    "        \n",
    "    return atom(token)\n",
    "\n",
    "def atom(token: str) -> Atom:\n",
    "    \"\"\"\n",
    "    Numbers remain numbers; every other token becomes a symbol.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(token)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return float(token)\n",
    "        except ValueError:\n",
    "            return Symbol(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(begin (define r 10) (* pi (* r r)))'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['begin', ['define', 'r', 10], ['*', 'pi', ['*', 'r', 'r']]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*TODO: make this a class\n",
    "#*TODO: consider other ways to update the global space and expand it by importing modules\n",
    "import math\n",
    "import operator as op\n",
    "\n",
    "def standard_env() -> Env:\n",
    "    \"An environment with some Scheme standard procedures.\"\n",
    "    env = Env()\n",
    "    env.update(vars(math)) # sin, cos, sqrt, pi, ...\n",
    "    env.update({\n",
    "        '+':op.add, '-':op.sub, '*':op.mul, '/':op.truediv, \n",
    "        '>':op.gt, '<':op.lt, '>=':op.ge, '<=':op.le, '=':op.eq, \n",
    "        'abs':     abs,\n",
    "        'append':  op.add,  \n",
    "        'apply':   lambda proc, args: proc(*args),\n",
    "        'begin':   lambda *x: x[-1],\n",
    "        'car':     lambda x: x[0],\n",
    "        'cdr':     lambda x: x[1:], \n",
    "        'cons':    lambda x,y: [x] + y,\n",
    "        'eq?':     op.is_, \n",
    "        'expt':    pow,\n",
    "        'equal?':  op.eq, \n",
    "        'length':  len, \n",
    "        'list':    lambda *x: List(x), \n",
    "        'list?':   lambda x: isinstance(x, List), \n",
    "        'map':     map,\n",
    "        'max':     max,\n",
    "        'min':     min,\n",
    "        'not':     op.not_,\n",
    "        'null?':   lambda x: x == [], \n",
    "        'number?': lambda x: isinstance(x, Number),  \n",
    "        'print':   print,\n",
    "        'procedure?': callable,\n",
    "        'round':   round,\n",
    "        'symbol?': lambda x: isinstance(x, Symbol),\n",
    "    })\n",
    "    return env\n",
    "\n",
    "global_env = standard_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(x: Exp, env=global_env) -> Exp:\n",
    "    \"\"\"\n",
    "    Evaluate an expression in an environment.\n",
    "    \"\"\"\n",
    "    if isinstance(x, Symbol):        # variable reference\n",
    "        return env[x]\n",
    "    if isinstance(x, Number):      # constant number\n",
    "        return x                \n",
    "    if x[0] == 'if':               # conditional\n",
    "        (_, test, conseq, alt) = x\n",
    "        result = eval(test,env)\n",
    "        exp = (conseq if eval(test, env) else alt)\n",
    "        return eval(exp, env)\n",
    "    if x[0] == 'define':           # definition\n",
    "        (_, symbol, exp) = x\n",
    "        env[symbol] = eval(exp, env)\n",
    "        return None\n",
    "    \n",
    "    # Procedure call.\n",
    "    proc = eval(x[0], env)\n",
    "    args = [eval(arg, env) for arg in x[1:]]\n",
    "    return proc(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314.1592653589793"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(parse(program))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(program: str) -> Exp:\n",
    "    return eval(parse(program))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(begin (define r 10) (* pi (* r r)))\n"
     ]
    }
   ],
   "source": [
    "print(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314.1592653589793"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction: REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repl(prompt='> '):\n",
    "    \"\"\"\n",
    "    A prompt-read-eval-print loop.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        text = input(prompt)\n",
    "        if text == 'exit':\n",
    "            break\n",
    "        val = eval(parse(text))\n",
    "        if val is not None: \n",
    "            print(unparse(val))\n",
    "\n",
    "def unparse(exp):\n",
    "    \"\"\"\n",
    "    Convert an expression's internal representation Python object back into a parsable string.\n",
    "    \"\"\"\n",
    "    if isinstance(exp, List):\n",
    "        return '(' + ' '.join(map(unparse, exp)) + ')' \n",
    "    else:\n",
    "        return str(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this:\n",
    "```\n",
    "repl()\n",
    "(+ 1 2)\n",
    "exit\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> (+ 1 2)\n",
      "3\n",
      "> exit\n"
     ]
    }
   ],
   "source": [
    "repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this:\n",
    "```\n",
    "repl()\n",
    "> (define r 10)\n",
    "> (* pi (* r r))\n",
    "314.1592653589793\n",
    "> (if (> (* 11 11) 12) (* 7 6) oops)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run('(if (> 1 2) 1 0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"\"\"\n",
    "    (if (> (* 11 11) 12) (* 7 6) oops)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"\"\"\n",
    "    (list (+ 1 1) (+ 2 2) (* 2 3) (expt 2 3))\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Env a Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env(dict):\n",
    "    \"\"\"\n",
    "    An environment is a dict of name value pairs, with an outer Env.\n",
    "    \"\"\"\n",
    "    def __init__(self, parms=(), args=(), outer: Env=None):\n",
    "        \"\"\"\n",
    "        @param parms: Variable names to bind arguments to.\n",
    "        @param args: Values to bind the variable names to.\n",
    "        \"\"\"\n",
    "        self.update(zip(parms, args))\n",
    "        self.outer = outer\n",
    "    \n",
    "    def find(self, var: str) -> Env:\n",
    "        \"\"\"\n",
    "        Finds the innermost Env where the given name appears.\n",
    "        @param var: The name of the variable we're looking for.\n",
    "        @returns Env: The environment in which this name appears.\n",
    "        \"\"\"\n",
    "        if var in self:\n",
    "            return self\n",
    "        return self.outer.find(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change global_env over to the new Env class.\n",
    "global_env = standard_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Procedure:\n",
    "    \"\"\"\n",
    "    A user-defined procedure with variable name bindings.\n",
    "    \"\"\"\n",
    "    def __init__(self, parms, body, env):\n",
    "        self.parms = parms\n",
    "        self.body = body\n",
    "        self.env = env\n",
    "    \n",
    "    def __call__(self, *args):\n",
    "        # Create an environment with bindings for this one invocation.\n",
    "        env = Env(self.parms, args, self.env)\n",
    "\n",
    "        return eval(self.body, env)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Figure out how to enable plugins into `eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(x: Exp, env=global_env) -> Exp:\n",
    "    \"\"\"\n",
    "    Evaluate an expression in an environment.\n",
    "    \"\"\"\n",
    "    if isinstance(x, Symbol):        # variable reference\n",
    "        return env.find(x)[x]\n",
    "\n",
    "    if not isinstance(x, List):      # constant number\n",
    "        return x\n",
    "    \n",
    "    op, *args = x\n",
    "    if op == 'quote':              # Quote an expression without evaluating it\n",
    "        return args[0]\n",
    "    \n",
    "    if op == 'if':               # conditional\n",
    "        (test, conseq, alt) = args\n",
    "        result = eval(test,env)\n",
    "        if result:\n",
    "            exp = conseq\n",
    "        else:\n",
    "            exp = alt\n",
    "        return eval(exp, env)\n",
    "\n",
    "    if op == 'define':           # definition\n",
    "        (symbol, exp) = args\n",
    "        env[symbol] = eval(exp, env)\n",
    "        return None\n",
    "\n",
    "    if op == 'set!':             # assignment\n",
    "        (symbol, exp) = args\n",
    "        env.find(symbol)[symbol] = eval(exp, env)\n",
    "        return None\n",
    "    \n",
    "    if op == 'lambda':           # procedure\n",
    "        (parms, body) = args\n",
    "        return Procedure(parms, body, env)\n",
    "        \n",
    "    # Procedure call.\n",
    "    proc = eval(x[0], env)\n",
    "    args = [eval(arg, env) for arg in x[1:]]\n",
    "    return proc(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define args  ['make-account', ['lambda', ['balance'], ['lambda', ['amt'], ['begin', ['set!', 'balance', ['+', 'balance', 'amt']], 'balance']]]]\n"
     ]
    }
   ],
   "source": [
    "run(\"\"\"\n",
    "    (define make-account\n",
    "        (lambda (balance)\n",
    "            (lambda (amt)\n",
    "                (begin (set! balance (+ balance amt))\n",
    "                        balance))))\n",
    "    (define account1 (make-account 100))\n",
    "    (account1 -20)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "(define make-account (lambda (balance) (lambda (amt) (begin (set! balance (+ balance amt)) balance))))\n",
    "\n",
    "\n",
    "(define account1 (make-account 100.00))\n",
    "(account1 -20.00)\n",
    "(define account1 (make-account 100.00))\n",
    "(account1 -20.00)\n",
    "(account1 -20.00)\n",
    "(define account2 (make-account 100.00))\n",
    "(account2 40)\n",
    "(account2 -10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> (define make-account (lambda (balance) (lambda (amt) (begin (set! balance (+ balance amt)) balance))))\n",
      "> (define account1 (make-account 100.00))\n",
      "> account1\n",
      "<__main__.Procedure object at 0x000002B8E6E84848>\n",
      "> (account1 -20.00)\n",
      "80.0\n",
      "> (account1 -20.00)\n",
      "60.0\n",
      "> (define account2 (make-account 100.00))\n",
      "> (account2 40)\n",
      "140.0\n",
      "> (account2 -10)\n",
      "130.0\n",
      "> exit\n"
     ]
    }
   ],
   "source": [
    "repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "First let's assemble a list of things we'd like to do.  Our goal is to write something non-trivial like Asteroids.  To do that there are a few things we need to add.\n",
    "\n",
    "### Must Have\n",
    "* [Tail Call Optimization](https://en.wikipedia.org/wiki/Tail_call)\n",
    "    * To write a simple game I need to iterate infinitely.  This means either TCO, or cheating by implementing an explicit loop structure and introduce a new keyword.\n",
    "* [Data Structures](https://www.csie.ntu.edu.tw/~course/10420/Resources/lp/node50.html)\n",
    "    * [Association Lists](https://www.csie.ntu.edu.tw/~course/10420/Resources/lp/node51.html)\n",
    "* Cleanup/exception handling.\n",
    "    * To write a game, I need to create graphics structures such as windows which need to be de-allocated if the game halts unexpectedly.\n",
    "* Stack traces\n",
    "    * We'll need to be able to report what the interpreter was doing when we, for example, reference a variable that doesn't exist.  To do that we'd probably change the parser to attach properties with each token detailing the file, line number, and character position.\n",
    "* Macros\n",
    "* Plugin/module architecture.\n",
    "    * I don't like needing to update `eval()` when we add new structures.  Should be able to load a module that uses either lisp or python functions that hook into `eval()`.\n",
    "* Interpreter object.  I'd like to have a top-level object to encapsulate a lot of these global variables.  This would also enable me to have multiple interpreters that don't interfere with each other.\n",
    "\n",
    "Take a moment and consider what we'd need to do to implement stack traces for error messages.  That's going to involve diving deep into the parser and tokenizer, maybe changing it to take objects instead of normal strings.\n",
    "    \n",
    "Some of these will require pretty significant rework of the code, and it'll be easy to get it wrong and break it.  It's time to make unit tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should our unit tests look like?  We could code them in Python, but let's code the above test in Lisp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "    (define make-account\n",
    "        (lambda (balance)\n",
    "            (lambda (amt)\n",
    "                (begin (set! balance (+ balance amt))\n",
    "                        balance))))\n",
    "    (define account1 (make-account 100))\n",
    "    (expect-equal 80.0 (account1 -20))\n",
    "    (expect-equal 60.0 (account1 -20))\n",
    "    \n",
    "    (define account2 (make-account 100))\n",
    "    (expect-equal 140.0 (account2 40))\n",
    "    (expect-equal 130.0 (account2 -10))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to implement an `expect-equal` function somehow.  And also we'll want to be able to make many such tests.  Having the interpreter object will be a good first step, so that we have a good clean framework for running the tests instead of having dangling global variables.  Let's move over to an actual codebase outside of the notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Unit Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to make a framework to make this unit testable.  We will start with a unit test that does basically nothing, to test that we are doing the right imports and that's it.  The code for this stage will be in the folder `ch2/`.\n",
    "\n",
    "#### ricolisp/interpreter.py\n",
    "```py\n",
    "class LispInterpreter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def run(code: str):\n",
    "        \"\"\"\n",
    "        Parse some code, execute it, and return the result.\n",
    "        \"\"\"\n",
    "```\n",
    "\n",
    "#### test/test_lisp.py\n",
    "```py\n",
    "import unittest\n",
    "\n",
    "from ricolisp import LispInterpreter\n",
    "\n",
    "class TestBasics(unittest.TestCase):\n",
    "    def test_basics(self):\n",
    "        li = LispInterpreter()\n",
    "```\n",
    "\n",
    "#### test-run.bat\n",
    "```\n",
    "python -m unittest -v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't look like we've done much here, but we've actually done 3 very important things that lay the foundation:\n",
    "1. **Created modules**.  We now have a `ricolisp` module where we can put our interpreter code.\n",
    "2. **Created a test module**.  We now have a python module called `test` where we have the tests for our Lisp interpreter.\n",
    "3. **Created a way to run the tests**.  We made a bat file for running the tests, which is also checked in.  Now we have a single place to change how tests are run in case that needs to change in the future.\n",
    "\n",
    "And does it run?\n",
    "```\n",
    "(base) D:\\code\\rico-lisp\\ch2>python -m unittest -v\n",
    "test_basics (test.test_lisp.TestBasics) ... ok\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 1 test in 0.001s\n",
    "\n",
    "OK\n",
    "```\n",
    "Looks good.  Now we can start to implement things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red, Green, Refactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general process we'll use as we implement something is:\n",
    "1. Write just enough of a unit test for that to make a test fail.\n",
    "2. Implement just enough of the code to make the unit test work.\n",
    "3. Rework the hacky code from step 2 to make it the way we want it.\n",
    "\n",
    "This approach is called \"Red, Green, Refactor\".\n",
    "1. **Red**.  Update your unit tests as if your code already did what the new feature requires, such that at least one of your unit tests start failing-- the tests go \"red\".\n",
    "2. **Green**.  Fix the code until the tests work.  It's ok if the fixes are sloppy, slow, naive, whatever.  We'll fix it soon.\n",
    "3. **Refactor**.  Fix anything that's not how you want.  You now have a basis or framework for proceeding with confidence, because you've got your tests.\n",
    "\n",
    "This isn't about writing sloppy code, it's actually about writing even better code.  Very often we will write something that we don't particularly like or aren't proud of, but we are afraid we will break something by trying to rework it.  Good unit testing lets us fearlessly rework the code with the added confidence that we will catch the problems during the testing.\n",
    "\n",
    "Note that we don't write all the unit tests for an entire feature, then write the feature, then refactor.  Instead what we do is very small loops of those 3 steps.  A tiny bit of test code, a tiny bit of feature code, a tiny bit of refactoring.  Then we incrementally build up both our application and the strength of our tests, together.  More details and wise thoughts about this are in this [Bob Martin article on The Cycles of TDD](https://blog.cleancoder.com/uncle-bob/2014/12/17/TheCyclesOfTDD.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser and Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by making a unit test that fails.  We do that by stealing from the early parts of our lisp implementation at the top of this notebook:\n",
    "\n",
    "#### test/test_lisp.py:\n",
    "```py\n",
    "    def test_tokenize(self):\n",
    "        source_code = \"(begin (define r 10) (* pi (* r r)))\"\n",
    "        expected_tokens = ['(', 'begin', '(', 'define', 'r', '10', ')',\n",
    "            '(', '*', 'pi', '(', '*', 'r', 'r', ')', ')', ')']\n",
    "\n",
    "        tokens = tokenize(source_code)\n",
    "        self.assertListEqual(expected_tokens, tokens)\n",
    "```\n",
    "\n",
    "#### ricolisp/token.py\n",
    "```py\n",
    "from typing import List\n",
    "\n",
    "def tokenize(chars: str) -> List[str]:\n",
    "    \"\"\"Convert a string of characters into a list of tokens.\"\"\"\n",
    "    return chars.replace('(', ' ( ').replace(')', ' ) ').split()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we basically redo the steps of the notebook starting at the top and proceeding down to here, putting the code into interpreter.py.  This notebook built lisp from the ground up, doing little tests of things as it went. We will repeat the same process, but this time we will build those little tests into unit tests.  When we've done that, we end up with the code that is sitting in the ch2/ folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add feature: While loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now the only form of looping we can do is recursion.  To do a long-running program without stack overflows we will need to either implement tail recursion or introduce our own looping construct into the language.  I'm going to keep it simple and introduce a loop primitive instead of doing tail recursion for now.\n",
    "\n",
    "I want to make a new `while` primitive that works like this:\n",
    "```\n",
    "(while condition statement)\n",
    "```\n",
    "The way it will work is to evaluate *condition*, then execute *statement* if that is true, and continue doing so until *condition* becomes false.\n",
    "\n",
    "We'll start with a unit test that fails:\n",
    "```py\n",
    "    def test_while(self):\n",
    "        self._start_console()\n",
    "        self._enter(\"\"\"\n",
    "            (define sumto (lambda (x)\n",
    "                (begin\n",
    "                    (define total 0)\n",
    "                    (while (> x 0)\n",
    "                        (begin\n",
    "                            (set! total (+ total x))\n",
    "                            (set! x (- x 1))\n",
    "                        )\n",
    "                    )\n",
    "                    total\n",
    "                )\n",
    "            ))\n",
    "        \"\"\")\n",
    "        self._enter('(sumto 4)', 10)\n",
    "        self._verify_console()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An implementation of this that works is a modification to the `eval()` function:\n",
    "```py\n",
    "    if op == 'while':\n",
    "        (cond, statement) = args\n",
    "        result = None\n",
    "        while True:\n",
    "            conditional_result = eval(cond, env)\n",
    "            if not conditional_result:\n",
    "                break\n",
    "            result = eval(statement, env)\n",
    "        return result\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
